{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "891897dd-0539-45ea-b83c-b0360ba8789c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.12.0 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (2.12.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.12.0 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from tensorflow==2.12.0) (2.12.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (25.1.24)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (3.12.1)\n",
      "Requirement already satisfied: jax>=0.3.15 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (0.4.30)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (18.1.1)\n",
      "Requirement already satisfied: numpy<1.24,>=1.22 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (1.23.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (4.25.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (4.12.2)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (1.70.0)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (2.12.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (2.12.0)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (2.12.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.0->tensorflow==2.12.0) (0.38.4)\n",
      "Requirement already satisfied: jaxlib<=0.4.30,>=0.4.27 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow==2.12.0) (0.4.30)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow==2.12.0) (0.4.1)\n",
      "Requirement already satisfied: scipy>=1.9 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow==2.12.0) (1.10.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (2.38.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (2.32.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (5.5.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (2.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (2024.12.14)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.12.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73e48697-6b42-4823-b4d7-de177ebe17f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from tensorflow.keras.layers import LeakyReLU, Activation, ZeroPadding2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow.keras import initializers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9780064b-1926-4068-ae07-c28ef58fa46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random seed to replicate results\n",
    "\n",
    "np.random.seed(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8a3d87d-09fd-473a-a19d-ae25f92eaa3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load MNIST data (Hand-written digits)\n",
    "\n",
    "def load_mnist():\n",
    "    (X_train, _), (_, _) = tf.keras.datasets.mnist.load_data()\n",
    "    X_train = (X_train.astype(np.float32) - 127.5)/127.5\n",
    "    X_train = X_train.reshape(60000, -1)\n",
    "    return X_train\n",
    "\n",
    "X_train = load_mnist()\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9a4398-7d5f-4075-ae48-fa93095b79c4",
   "metadata": {},
   "source": [
    "### GAN (Generative Adversarial Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8c67e0f-0891-46d4-abc7-8f0f6221d7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "\n",
    "adam = Adam(learning_rate=0.0002, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e6ac97c-bcf5-4d8f-9b75-55a6078d13a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build the generator\n",
    "\n",
    "def build_generator():\n",
    "    \n",
    "    model = Sequential([\n",
    "        Dense(256, input_dim=10),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "        Dense(512),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "        Dense(1024),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "        Dense(784, activation='tanh')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "generator = build_generator()\n",
    "generator.compile(loss='binary_crossentropy', optimizer=adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f1d9f49a-2c24-49e4-9e8d-96c61b8b802c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build the generator\n",
    "\n",
    "def build_discriminator():\n",
    "    \n",
    "    model = Sequential([\n",
    "        Dense(1024, input_dim=784, kernel_initializer=initializers.RandomNormal(stddev=0.02)),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "        Dropout(0.3),\n",
    "        Dense(512),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "        Dropout(0.3),\n",
    "        Dense(256),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "        Dropout(0.3),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "discriminator = build_discriminator()\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c66a90d7-238f-4274-8dd7-8d0250bffb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined network (GAN)\n",
    "\n",
    "discriminator.trainable = False\n",
    "ganInput = Input(shape=(10,))\n",
    "x = generator(ganInput)\n",
    "ganOutput = discriminator(x)\n",
    "gan = Model(inputs=ganInput, outputs=ganOutput)\n",
    "gan.compile(loss='binary_crossentropy', optimizer=adam)\n",
    "\n",
    "dLosses = []\n",
    "gLosses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7de5d501-ff71-4472-9ca6-474634b13160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss from each batch\n",
    "\n",
    "def plotLoss(epoch):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.plot(dLosses, label='Discriminitive loss')\n",
    "    plt.plot(gLosses, label='Generative loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig('GAN_images/gan_loss_epoch_%d.png' % epoch)\n",
    "\n",
    "# Create a wall of generated MNIST images\n",
    "\n",
    "def saveGeneratedImages(epoch, examples=100, dim=(10, 10), figsize=(10, 10)):\n",
    "    noise = np.random.normal(0, 1, size=[examples, 10])\n",
    "    generatedImages = generator.predict(noise, verbose = 0)\n",
    "    generatedImages = generatedImages.reshape(examples, 28, 28)\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(generatedImages.shape[0]):\n",
    "        plt.subplot(dim[0], dim[1], i+1)\n",
    "        plt.imshow(generatedImages[i], interpolation='nearest', cmap='gray_r')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('GAN_images\\digits_epoch_%d.png' % epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5d8aa11e-b849-4d53-8f0e-ec31a21a0b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs=1, batchSize=128):\n",
    "    batchCount = int(X_train.shape[0] / batchSize)\n",
    "    print ('Epochs:', epochs)\n",
    "    print ('Batch size:', batchSize)\n",
    "    print ('Batches per epoch:', batchCount)\n",
    "\n",
    "    for e in range(1, epochs+1):\n",
    "        print(f\" ======= Epoch {e} | Generator Loss: {prev_gloss:.4f} ======= \") if e > 1 else print(f\" ======= Epoch {e}\")\n",
    "        \n",
    "        for i in range(batchCount):\n",
    "            # Get a random set of input noise and images\n",
    "            noise = np.random.normal(0, 1, size=[batchSize, 10])\n",
    "            imageBatch = X_train[np.random.randint(0, X_train.shape[0], size=batchSize)]\n",
    "            \n",
    "            # Generate fake MNIST images\n",
    "            generatedImages = generator.predict(noise, verbose=0)\n",
    "            X = np.concatenate([imageBatch, generatedImages])\n",
    "            \n",
    "            # Labels for generated and real data\n",
    "            yDis = np.zeros(2*batchSize)\n",
    "            yDis[:batchSize] = 0.9  # One-sided label smoothing\n",
    "            \n",
    "            # Train discriminator\n",
    "            discriminator.trainable = True\n",
    "            dloss = discriminator.train_on_batch(X, yDis)\n",
    "            \n",
    "            # Train generator\n",
    "            noise = np.random.normal(0, 1, size=[batchSize, 10])\n",
    "            yGen = np.ones(batchSize)\n",
    "            discriminator.trainable = False\n",
    "            gloss = gan.train_on_batch(noise, yGen)\n",
    "            \n",
    "            # Print batch progress every 10 batches\n",
    "            if (i + 1) % 10 == 0:\n",
    "                print(f\"\\rBatch {i + 1}\", end='', flush=True)\n",
    "        \n",
    "        # Clear the batch line at the end of epoch\n",
    "        print('\\r' + ' ' * 20 + '\\r', end='', flush=True)  # Clear the batch line\n",
    "                \n",
    "        # Store loss of most recent batch from this epoch\n",
    "        dLosses.append(dloss)\n",
    "        gLosses.append(gloss)\n",
    "        prev_gloss = gloss  # Store current gloss for next epoch's print\n",
    "        \n",
    "        if e == 1 or e % 20 == 0:\n",
    "            saveGeneratedImages(e)\n",
    "    \n",
    "    # Plot losses from every epoch\n",
    "    plotLoss(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39b2547-7f20-44ef-9729-2c97a90b0bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 200\n",
      "Batch size: 128\n",
      "Batches per epoch: 468\n",
      " ======= Epoch 1\n",
      " ======= Epoch 2 | Generator Loss: 1.3673 ======= \n",
      " ======= Epoch 3 | Generator Loss: 2.6297 ======= \n",
      " ======= Epoch 4 | Generator Loss: 1.7228 ======= \n",
      " ======= Epoch 5 | Generator Loss: 1.2494 ======= \n",
      " ======= Epoch 6 | Generator Loss: 1.3618 ======= \n",
      " ======= Epoch 7 | Generator Loss: 1.5052 ======= \n",
      " ======= Epoch 8 | Generator Loss: 1.2839 ======= \n",
      " ======= Epoch 9 | Generator Loss: 1.2102 ======= \n",
      " ======= Epoch 10 | Generator Loss: 1.3327 ======= \n",
      " ======= Epoch 11 | Generator Loss: 1.2104 ======= \n",
      " ======= Epoch 12 | Generator Loss: 1.3272 ======= \n",
      " ======= Epoch 13 | Generator Loss: 0.9988 ======= \n",
      " ======= Epoch 14 | Generator Loss: 1.1673 ======= \n",
      " ======= Epoch 15 | Generator Loss: 1.0470 ======= \n",
      " ======= Epoch 16 | Generator Loss: 1.0249 ======= \n",
      " ======= Epoch 17 | Generator Loss: 1.1693 ======= \n",
      " ======= Epoch 18 | Generator Loss: 1.2581 ======= \n",
      " ======= Epoch 19 | Generator Loss: 1.2504 ======= \n",
      " ======= Epoch 20 | Generator Loss: 0.9424 ======= \n",
      " ======= Epoch 21 | Generator Loss: 0.9697 ======= \n",
      " ======= Epoch 22 | Generator Loss: 1.0891 ======= \n",
      " ======= Epoch 23 | Generator Loss: 1.1519 ======= \n",
      " ======= Epoch 24 | Generator Loss: 0.9997 ======= \n",
      " ======= Epoch 25 | Generator Loss: 1.1352 ======= \n",
      " ======= Epoch 26 | Generator Loss: 1.1734 ======= \n",
      " ======= Epoch 27 | Generator Loss: 1.2320 ======= \n",
      " ======= Epoch 28 | Generator Loss: 1.1649 ======= \n",
      " ======= Epoch 29 | Generator Loss: 1.2160 ======= \n",
      " ======= Epoch 30 | Generator Loss: 1.0719 ======= \n",
      " ======= Epoch 31 | Generator Loss: 1.2044 ======= \n",
      " ======= Epoch 32 | Generator Loss: 1.0255 ======= \n",
      " ======= Epoch 33 | Generator Loss: 0.9433 ======= \n",
      " ======= Epoch 34 | Generator Loss: 0.9555 ======= \n",
      " ======= Epoch 35 | Generator Loss: 1.1016 ======= \n",
      " ======= Epoch 36 | Generator Loss: 1.1971 ======= \n",
      " ======= Epoch 37 | Generator Loss: 1.0822 ======= \n",
      " ======= Epoch 38 | Generator Loss: 1.1626 ======= \n",
      " ======= Epoch 39 | Generator Loss: 1.0939 ======= \n",
      " ======= Epoch 40 | Generator Loss: 1.0849 ======= \n",
      " ======= Epoch 41 | Generator Loss: 1.1268 ======= \n",
      " ======= Epoch 42 | Generator Loss: 1.0645 ======= \n",
      " ======= Epoch 43 | Generator Loss: 1.0464 ======= \n",
      " ======= Epoch 44 | Generator Loss: 1.1230 ======= \n",
      " ======= Epoch 45 | Generator Loss: 1.1255 ======= \n",
      " ======= Epoch 46 | Generator Loss: 1.1161 ======= \n",
      " ======= Epoch 47 | Generator Loss: 0.9880 ======= \n",
      " ======= Epoch 48 | Generator Loss: 1.0862 ======= \n",
      " ======= Epoch 49 | Generator Loss: 1.2466 ======= \n",
      " ======= Epoch 50 | Generator Loss: 0.9998 ======= \n",
      " ======= Epoch 51 | Generator Loss: 1.1780 ======= \n",
      " ======= Epoch 52 | Generator Loss: 1.1883 ======= \n",
      " ======= Epoch 53 | Generator Loss: 1.1699 ======= \n",
      " ======= Epoch 54 | Generator Loss: 1.1593 ======= \n",
      " ======= Epoch 55 | Generator Loss: 1.0839 ======= \n",
      " ======= Epoch 56 | Generator Loss: 0.8794 ======= \n",
      " ======= Epoch 57 | Generator Loss: 1.0129 ======= \n",
      " ======= Epoch 58 | Generator Loss: 1.0594 ======= \n",
      " ======= Epoch 59 | Generator Loss: 1.1535 ======= \n",
      "Batch 320"
     ]
    }
   ],
   "source": [
    "train(200, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768245b9-bf7f-442f-9d7d-f04bf92ae329",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c39090-38eb-4ce2-b055-75e5dce728b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
