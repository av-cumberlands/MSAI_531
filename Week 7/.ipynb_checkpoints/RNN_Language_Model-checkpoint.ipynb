{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae77f614-5d16-403e-a8d0-39b1db6cb700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\alex-\\anaconda3\\lib\\site-packages (2.12.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.12.0 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (25.1.24)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.12.1)\n",
      "Requirement already satisfied: jax>=0.3.15 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.30)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: numpy<1.24,>=1.22 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.23.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.25.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.70.0)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: jaxlib<=0.4.30,>=0.4.27 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (0.4.30)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: scipy>=1.9 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (1.10.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.38.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (5.5.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2024.12.14)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\alex-\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00b16a60-6c47-4b76-b39b-f24aff6b8424",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "import tensorflow as tf\n",
    "\n",
    "DATA_DIR = \"./data\"\n",
    "CHECKPOINT_DIR = os.path.join(DATA_DIR, \"checkpoints\")\n",
    "LOG_DIR = os.path.join(DATA_DIR, \"logs\")\n",
    "\n",
    "def download_and_read(urls):\n",
    "    texts = []\n",
    "    for i, url in enumerate(urls):\n",
    "        p = tf.keras.utils.get_file(\"ex1-{:d}.txt\".format(i), url,\n",
    "            cache_dir=\".\")\n",
    "        text = open(p, mode=\"r\", encoding=\"utf-8\").read()\n",
    "        # Remove byte order mark\n",
    "        text = text.replace(\"\\ufeff\", \"\")\n",
    "        # Remove newlines\n",
    "        text = text.replace('\\n', ' ')\n",
    "        text = re.sub(r'\\s+', \" \", text)\n",
    "        # Add it to the list\n",
    "        texts.extend(text)\n",
    "    return texts\n",
    "\n",
    "def split_train_labels(sequence):\n",
    "    input_seq = sequence[0:-1]\n",
    "    output_seq = sequence[1:]\n",
    "    return input_seq, output_seq\n",
    "\n",
    "class CharGenModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, vocab_size, num_timesteps, \n",
    "            embedding_dim, **kwargs):\n",
    "        super(CharGenModel, self).__init__(**kwargs)\n",
    "        self.embedding_layer = tf.keras.layers.Embedding(\n",
    "            vocab_size,\n",
    "            embedding_dim\n",
    "        )\n",
    "        self.rnn_layer = tf.keras.layers.GRU(\n",
    "            num_timesteps,\n",
    "            recurrent_initializer=\"glorot_uniform\",\n",
    "            recurrent_activation=\"sigmoid\",\n",
    "            stateful=True,\n",
    "            return_sequences=True\n",
    "        )\n",
    "        self.dense_layer = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.embedding_layer(x)\n",
    "        x = self.rnn_layer(x)\n",
    "        x = self.dense_layer(x)\n",
    "        return x\n",
    "\n",
    "def loss(labels, predictions):\n",
    "    return tf.losses.sparse_categorical_crossentropy(\n",
    "        labels,\n",
    "        predictions,\n",
    "        from_logits=True\n",
    "    )\n",
    "\n",
    "def generate_text(model, prefix_string, char2idx, idx2char,\n",
    "        num_chars_to_generate=1000, temperature=1.0):\n",
    "    input = [char2idx[s] for s in prefix_string]\n",
    "    input = tf.expand_dims(input, 0)\n",
    "    text_generated = []\n",
    "    model.reset_states()\n",
    "    for i in range(num_chars_to_generate):\n",
    "        preds = model(input)\n",
    "        preds = tf.squeeze(preds, 0) / temperature\n",
    "        # Predict char returned by model\n",
    "        pred_id = tf.random.categorical(preds, num_samples=1)[-1, 0].numpy()\n",
    "        text_generated.append(idx2char[pred_id])\n",
    "        # Pass the prediction as the next input to the model\n",
    "        input = tf.expand_dims([pred_id], 0)\n",
    "\n",
    "    return prefix_string + \"\".join(text_generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe651ca-2052-4843-bfb2-12d595a94f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size: 93\n",
      "input:[The Project Gutenberg eBook of Alice's Adventures in Wonderland This ebook is for the use of anyone ]\n",
      "output:[he Project Gutenberg eBook of Alice's Adventures in Wonderland This ebook is for the use of anyone a]\n",
      "<_BatchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int32, name=None), TensorSpec(shape=(64, 100), dtype=tf.int32, name=None))>\n",
      "Model: \"char_gen_model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     multiple                  23808     \n",
      "                                                                 \n",
      " gru_2 (GRU)                 multiple                  107400    \n",
      "                                                                 \n",
      " dense_2 (Dense)             multiple                  9393      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 140,601\n",
      "Trainable params: 140,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "(64, 100, 93)\n",
      "Epoch 1/10\n",
      "51/51 [==============================] - 12s 207ms/step - loss: 3.5219\n",
      "Epoch 2/10\n",
      "51/51 [==============================] - 9s 176ms/step - loss: 2.8202\n",
      "Epoch 3/10\n",
      "51/51 [==============================] - 9s 182ms/step - loss: 2.5078\n",
      "Epoch 4/10\n",
      "51/51 [==============================] - 9s 178ms/step - loss: 2.3515\n",
      "Epoch 5/10\n",
      "51/51 [==============================] - 8s 159ms/step - loss: 2.2389\n",
      "Epoch 6/10\n",
      "51/51 [==============================] - 9s 173ms/step - loss: 2.1333\n",
      "Epoch 7/10\n",
      "51/51 [==============================] - 11s 217ms/step - loss: 2.0570\n",
      "Epoch 8/10\n",
      "51/51 [==============================] - 12s 231ms/step - loss: 2.0001\n",
      "Epoch 9/10\n",
      "51/51 [==============================] - 13s 260ms/step - loss: 1.9429\n",
      "Epoch 10/10\n",
      "51/51 [==============================] - 10s 196ms/step - loss: 1.8922\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._iterations\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._learning_rate\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
      "======================================== Generated text after epoch 10: ========================================\n",
      "Alice spiveric_ to alls peething Alice Haw and seere thing havt and of the atfnothow to fenter fureg, efpace a dried, dyood the Queen, she twas of itis whet bory the plach-\" Mine lawing to rithar boor the srous here knise by, and no mith than to ell) It of seep thate-as hely,” she dreesseer to nel!” Aplets, lrigched to poated it op, and the Dowhn’t, with in wist wearsair and to said “To freple vere troum tome catly es loove! Cher poust’s aven licktide thelf sousht daisber), ·out in is my ut to net it ange goblaryy digh's har _ibfed that feres, if salding, __say hy,” (for), \"Nook, you the trisalice srold her took ear can’t allainginged. \"Heen niquid she markers queg. \"LiP--fow har it all,\" The eackne uchion whis of the ith—wHiyed _hen a enref ittligh _Alice strerution't meed lo the ull,\" said_?\" the Dume afplytt oning efeated ong hit for and then she King trice beed lifbokers,\" say beced ithich, I throuln ind the gowed and but mame than thim juers see, whe gettill it them ok soing vanter hour\n",
      "---\n",
      "Epoch 1/10\n",
      "51/51 [==============================] - 8s 154ms/step - loss: 1.8523\n",
      "Epoch 2/10\n",
      "51/51 [==============================] - 10s 188ms/step - loss: 1.8139\n",
      "Epoch 3/10\n",
      "51/51 [==============================] - 10s 194ms/step - loss: 1.7844\n",
      "Epoch 4/10\n",
      "51/51 [==============================] - 9s 185ms/step - loss: 1.7531\n",
      "Epoch 5/10\n",
      "51/51 [==============================] - 9s 171ms/step - loss: 1.7222\n",
      "Epoch 6/10\n",
      "51/51 [==============================] - 9s 182ms/step - loss: 1.7006\n",
      "Epoch 7/10\n",
      "51/51 [==============================] - 9s 171ms/step - loss: 1.6804\n",
      "Epoch 8/10\n",
      "51/51 [==============================] - 9s 168ms/step - loss: 1.6585\n",
      "Epoch 9/10\n",
      "51/51 [==============================] - 10s 191ms/step - loss: 1.6403\n",
      "Epoch 10/10\n",
      "51/51 [==============================] - 10s 193ms/step - loss: 1.6217\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._iterations\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._learning_rate\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
      "======================================== Generated text after epoch 20: ========================================\n",
      "Alice was on wherevertan by you pleang incounnter’s taking an one. \"U/onect fe fel.” After his faronap, “by have agent, fur in misht Huthe to it is?\" samn monerses, a_d better, pust hered thing a just sem, aqubt that tales kinking meandead-on. “Weet; “wo herself,” said, that _I_d’t dneverself) Just little told me out op, pre agin over he simo, that, dory of she fe_ and welt to!” \"The moment, said fent to sipsess. She glouty inself the horse adding—I one, \"that; she last plomende’f teaphers, ain hell wo his _thought stopt. “Oh timby this driselbed belongers me aptended not onsten misther straw.\" \"Abtule, and it?\" Turt it wyreaging his way the rest of it, 1or,” seet as said then the realfance moesed onseld, bet she could wakn try, that enthing of very-is comrea long thems, with a comet, and And helver appect of chen of off his eng.\" you kenelver Ray_'” “the other Project know poiles Gr; \"_Sheed on an enwilent that.\" she time with so dos at for arstaingwher,\" said the Gry, knith himbusiond’t th\n",
      "---\n",
      "Epoch 1/10\n",
      "35/51 [===================>..........] - ETA: 2s - loss: 1.6089"
     ]
    }
   ],
   "source": [
    "# Download and read into local data structure (list of chars)\n",
    "texts = download_and_read([\n",
    "    \"http://www.gutenberg.org/cache/epub/28885/pg28885.txt\",\n",
    "    \"https://www.gutenberg.org/files/12/12-0.txt\"\n",
    "])\n",
    "\n",
    "# Create the vocabulary\n",
    "vocab = sorted(set(texts))\n",
    "print(\"vocab size: {:d}\".format(len(vocab)))\n",
    "\n",
    "# Create mapping from vocab chars to ints\n",
    "char2idx = {c:i for i, c in enumerate(vocab)}\n",
    "idx2char = {i:c for c, i in char2idx.items()}\n",
    "\n",
    "# Numerize the texts\n",
    "texts_as_ints = np.array([char2idx[c] for c in texts])\n",
    "data = tf.data.Dataset.from_tensor_slices(texts_as_ints)\n",
    "\n",
    "# Number of characters to show before asking for prediction\n",
    "# Sequences: [None, 100]\n",
    "seq_length = 100\n",
    "sequences = data.batch(seq_length + 1, drop_remainder=True)\n",
    "sequences = sequences.map(split_train_labels)\n",
    "\n",
    "# Print out input and output to see what they look like\n",
    "for input_seq, output_seq in sequences.take(1):\n",
    "    print(\"input:[{:s}]\".format(\n",
    "        \"\".join([idx2char[i] for i in input_seq.numpy()])))\n",
    "    print(\"output:[{:s}]\".format(\n",
    "        \"\".join([idx2char[i] for i in output_seq.numpy()])))\n",
    "\n",
    "# Set up for training\n",
    "batch_size = 64\n",
    "steps_per_epoch = len(texts) // seq_length // batch_size\n",
    "dataset = sequences.shuffle(10000).batch(batch_size, drop_remainder=True)\n",
    "print(dataset)\n",
    "\n",
    "# Define network\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 256\n",
    "\n",
    "model = CharGenModel(vocab_size, seq_length, embedding_dim)\n",
    "model.build(input_shape=(batch_size, seq_length))\n",
    "model.summary()\n",
    "\n",
    "# Try running some data through the model to validate dimensions\n",
    "for input_batch, label_batch in dataset.take(1):\n",
    "    pred_batch = model(input_batch)\n",
    "\n",
    "print(pred_batch.shape)\n",
    "assert(pred_batch.shape[0] == batch_size)\n",
    "assert(pred_batch.shape[1] == seq_length)\n",
    "assert(pred_batch.shape[2] == vocab_size)\n",
    "\n",
    "model.compile(optimizer=tf.optimizers.Adam(), loss=loss)\n",
    "\n",
    "# We will train our model for 50 epochs and after every 10 epochs we want to see how well it will generate text\n",
    "num_epochs = 50\n",
    "for i in range(num_epochs // 10):\n",
    "    model.fit(\n",
    "        dataset.repeat(),\n",
    "        epochs=10,\n",
    "        steps_per_epoch=steps_per_epoch\n",
    "        # callbacks=[checkpoint_callback, tensorboard_callback]\n",
    "    )\n",
    "    checkpoint_file = os.path.join(\n",
    "        CHECKPOINT_DIR, \"model_epoch_{:d}\".format(i+1))\n",
    "    model.save_weights(checkpoint_file)\n",
    "\n",
    "    # Create a generative model using the trained model so far\n",
    "    gen_model = CharGenModel(vocab_size, seq_length, embedding_dim)\n",
    "    gen_model.load_weights(checkpoint_file)\n",
    "    gen_model.build(input_shape=(1, seq_length))\n",
    "\n",
    "    print(f\"======================================== Generated text after epoch {(i+1) * 10}: ========================================\")\n",
    "    print(generate_text(gen_model, \"Alice \", char2idx, idx2char))\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ddd287-726e-4409-b0b2-17f4b9fbdf3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
